---
title: "Detecting machine generated text"
date: 2023-08-30
author: Nitin
---

The adoption of LLM models and the output generated by them is going to proliferate the data that we are going to consume in the future. Now that is not necessary alarming, but sometimes, there can be a need to understand what is generate by a machine vs what is generated by a human. This blog covers some of the methods that can help there

## Why you might need it?

Regulation is a term that is thrown around a lot in the data science community to try 'rein in' the dangers posed by generative AI models. There are many dimensions to it and is a topic that requires a separate discussion. But there are certain areas where this can be helpful. Like -
* Compliance

## Techniques
1. Proactive: Watermark embedded in the generated text. There are 2 approaches depending on the level of access to the text generation model:
    1. White box model: If you have a white box model, you have access to the token/text generation step. By modifying the tokens you can embed the watermark in the generated text
    2. Black box model: If you have a black box model, where you can just access the generated text, then there are options to to post processing on the generated text by using another model
    Once the watermark is embedded you can use statistical test to determine if the text was generated by that model
2. Reactive: Not all models have watermark embedded in the text. So instead of detecting the watermark we have to extract other signals from the text to determine if it's a machine generated or human generated one. That is mostly done using perturbation methods to estimate the local log probability curvature. There can be again 2 approaches, depending on the level of access to the model:
    1. White box model: Use the log probabilities of the white box model itself
    2. Black box model: Use the log probabilites of a surriogate model to estimat the log probs of the black box model

